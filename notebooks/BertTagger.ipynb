{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn Struct.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvardnlp/pytorch-struct/blob/master/notebooks/BertTagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpuauEFHAptc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "fa3304f4-209e-4d02-9d9f-241c466ebe15"
      },
      "source": [
        "!pip install -q torchtext\n",
        "!pip install -q pytorch-transformers\n",
        "!pip install -qU git+https://github.com/harvardnlp/pytorch-struct"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 184kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 59.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 808kB 52.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 62.6MB/s \n",
            "\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-struct (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF4__YMPArMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3adcaab5-edb2-4808-c62e-9a84cc113b7a"
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torch_struct import LinearChain, MaxSemiring\n",
        "import torch_struct.data\n",
        "from pytorch_transformers import *\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 213450/213450 [00:00<00:00, 303952.00B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rCPFdKJ-n4q",
        "colab_type": "text"
      },
      "source": [
        "Setup data and batching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWrGLRmJC89K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3f6bbd0f-a539-4ec4-fd94-3d2af669a764"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = BertModel, BertTokenizer, 'bert-base-cased'\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)    \n",
        "WORD = torch_struct.data.SubTokenizedField(tokenizer)\n",
        "UD_TAG = torchtext.data.Field(init_token=\"<bos>\", eos_token=\"<eos>\", include_lengths=True)\n",
        "\n",
        "# Download and the load default data.\n",
        "train, val, test = torchtext.datasets.UDPOS.splits(\n",
        "    fields=(('word', WORD), ('udtag', UD_TAG), (None, None)), \n",
        "    filter_pred=lambda ex: len(ex.word[0]) < 50\n",
        ")\n",
        "\n",
        "#WORD.build_vocab(train.word, min_freq=3)\n",
        "UD_TAG.build_vocab(train.udtag)\n",
        "train_iter = torch_struct.data.TokenBucket(train, 1500)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading en-ud-v2.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 1.55MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n",
            "error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss7plawBHR_A",
        "colab_type": "text"
      },
      "source": [
        "Setup transformer and a simple one-layer model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvUmy1gZAuZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "model.cuda()\n",
        "C = len(UD_TAG.vocab)\n",
        "H = 768\n",
        "linear = torch.zeros(H, C).cuda().requires_grad_(True)\n",
        "linear.data.normal_(mean=0, std=0.02)\n",
        "transition = torch.zeros(C, C).cuda().requires_grad_(True)\n",
        "transition.data.normal_(mean=0, std=0.02)\n",
        "\n",
        "opt = AdamW([linear, transition] + list(model.parameters()), lr=1e-4, eps=1e-8)\n",
        "scheduler = WarmupLinearSchedule(opt, warmup_steps=20, t_total=2500)\n",
        "def potentials(words, mapper):\n",
        "    out = model(words)\n",
        "    out = torch.nn.functional.dropout(out[0], p=0.1, training=model.training)\n",
        "    out = torch.einsum(\"bca,bch->bah\", mapper.float().cuda(), out)\n",
        "    final = torch.einsum(\"bnh,hc->bnc\", out, linear)\n",
        "    batch, N, C = final.shape\n",
        "    vals = final.view(batch, N, C, 1)[:, 1:N] + transition.view(1, 1, C, C)\n",
        "    vals[:, 0, :, :] += final.view(batch, N, 1, C)[:, 0] \n",
        "    return vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuCDtMSk-x2R",
        "colab_type": "text"
      },
      "source": [
        "Generic train validation loop. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEv1xeZl1Qux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_iter = torchtext.data.BucketIterator(val, \n",
        "    batch_size=20,\n",
        "    device=\"cuda:0\")\n",
        "\n",
        "def validate(itera):\n",
        "    incorrect_edges = 0\n",
        "    total = 0 \n",
        "    model.eval()\n",
        "    for i, ex in enumerate(itera):\n",
        "        words, mapper, _ = ex.word\n",
        "        label, lengths = ex.udtag\n",
        "        final = potentials(words.cuda(), mapper)\n",
        "        argmax = LinearChain(MaxSemiring).marginals(final, lengths=lengths)\n",
        "        gold = LinearChain.to_parts(label.transpose(0, 1), C,\n",
        "                                    lengths=lengths).type_as(argmax)\n",
        "        incorrect_edges += (argmax.sum(-1) - gold.sum(-1)).abs().sum() / 2.0\n",
        "        total += argmax[:, :].sum()            \n",
        "        #if i == 50:\n",
        "        #    break\n",
        "    print(incorrect_edges, total)   \n",
        "    model.train()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for i, ex in enumerate(train_iter):\n",
        "        opt.zero_grad()\n",
        "        words, mapper, _ = ex.word\n",
        "        label, lengths = ex.udtag\n",
        "        N_1, batch = label.shape\n",
        "        # Model\n",
        "        final = potentials(words.cuda(), mapper)\n",
        "        \n",
        "        if not lengths.max() <= final.shape[1] + 1:\n",
        "            print(\"fail\")\n",
        "            continue\n",
        "        \n",
        "        log_partition = LinearChain().sum(final, lengths=lengths)\n",
        "        labels = LinearChain.to_parts(label.transpose(0, 1), C, lengths=lengths) \\\n",
        "                            .type_as(final)\n",
        "        log_prob = LinearChain().score(final, labels) - log_partition\n",
        "        loss = log_prob.sum()\n",
        "        (-loss).backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "        scheduler.step()\n",
        "        opt.zero_grad()\n",
        "        losses.append(loss.detach())\n",
        "        if i % 50 == 1:            \n",
        "            print(-torch.tensor(losses).mean(), words.shape)\n",
        "            losses = []\n",
        "        if i % 600 == 1:\n",
        "            validate(val_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvb0rbD90gJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9574ce5a-7d38-4989-a2dd-eb5d02524300"
      },
      "source": [
        "train()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4135.5098) torch.Size([116, 13])\n",
            "tensor(12609., device='cuda:0') tensor(12790., device='cuda:0')\n",
            "tensor(1918.0920) torch.Size([300, 5])\n",
            "tensor(689.8613) torch.Size([75, 20])\n",
            "tensor(464.5420) torch.Size([88, 17])\n",
            "tensor(316.9471) torch.Size([117, 13])\n",
            "tensor(306.2497) torch.Size([68, 22])\n",
            "tensor(258.1658) torch.Size([46, 33])\n",
            "tensor(186.1516) torch.Size([58, 26])\n",
            "tensor(174.9373) torch.Size([47, 32])\n",
            "tensor(171.7171) torch.Size([147, 11])\n",
            "tensor(141.1298) torch.Size([31, 49])\n",
            "tensor(120.0469) torch.Size([37, 41])\n",
            "tensor(124.4972) torch.Size([127, 12])\n",
            "tensor(902., device='cuda:0') tensor(12704., device='cuda:0')\n",
            "tensor(94.6860) torch.Size([300, 4])\n",
            "tensor(91.4593) torch.Size([65, 23])\n",
            "tensor(79.3262) torch.Size([43, 35])\n",
            "tensor(83.9711) torch.Size([35, 43])\n",
            "tensor(63.0983) torch.Size([60, 25])\n",
            "tensor(62.3029) torch.Size([57, 26])\n",
            "tensor(62.7254) torch.Size([111, 14])\n",
            "tensor(46.1658) torch.Size([50, 30])\n",
            "tensor(63.7202) torch.Size([62, 24])\n",
            "tensor(41.7853) torch.Size([107, 14])\n",
            "tensor(39.2360) torch.Size([65, 23])\n",
            "tensor(40.3170) torch.Size([43, 35])\n",
            "tensor(664., device='cuda:0') tensor(12524., device='cuda:0')\n",
            "tensor(46.3819) torch.Size([60, 25])\n",
            "tensor(29.8644) torch.Size([57, 26])\n",
            "tensor(34.2502) torch.Size([32, 47])\n",
            "tensor(32.3574) torch.Size([41, 37])\n",
            "tensor(21.5847) torch.Size([46, 33])\n",
            "tensor(31.1177) torch.Size([118, 13])\n",
            "tensor(27.4312) torch.Size([69, 22])\n",
            "tensor(17.6033) torch.Size([257, 7])\n",
            "tensor(25.1966) torch.Size([41, 37])\n",
            "tensor(23.3278) torch.Size([34, 43])\n",
            "tensor(16.6685) torch.Size([78, 19])\n",
            "tensor(16.8195) torch.Size([34, 44])\n",
            "tensor(745., device='cuda:0') tensor(12912., device='cuda:0')\n",
            "tensor(12.6101) torch.Size([57, 26])\n",
            "tensor(18.9692) torch.Size([104, 15])\n",
            "tensor(13.6596) torch.Size([57, 26])\n",
            "tensor(12.0340) torch.Size([85, 18])\n",
            "tensor(13.8152) torch.Size([32, 47])\n",
            "tensor(9.7258) torch.Size([53, 28])\n",
            "tensor(13.0585) torch.Size([93, 17])\n",
            "tensor(8.1839) torch.Size([75, 20])\n",
            "tensor(10.2540) torch.Size([57, 26])\n",
            "tensor(8.6184) torch.Size([69, 22])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-27a563ba6b5f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}